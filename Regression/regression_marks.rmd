---
title: "reg_class_marks"
author: "Nick Marks"
date: "12/7/2017"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
library(pacman)
p_load(caret)
p_load(ggplot2)
p_load(plyr)    # need to load before dplyr due to presense of plyr still in gbm
p_load(dplyr)
p_load(Hmisc)
p_load(magrittr)
p_load(tidyr)
p_load(scales)
p_load(rms)
p_load(broom)
p_load(stargazer)
p_load(knitr)
p_load(emisc)
p_load(magrittr)

knitr::opts_chunk$set(comment = NULL)

options(scipen = 9) # eliminate scientific notation
movie_folder_id = 13948823224

old <- theme_get()
the_new <- old %+% theme(text = element_text(family = "HelveticaNeue-Light"),
    panel.background = element_rect(fill = "transparent",colour = NA),
  panel.grid.major = element_line(colour = "grey"))
theme_set(the_new)

set.seed(20161123)  # get the same results when using stochastic functions
```


# 1. First make sure that you can run the code in this class.

```{r load_data}
pacman::p_load(eboxr)
transactions <- eboxr_read("/Users/curtbergmann/Box Sync/Elicit Education/scholar/regclass/transactions.RDS",
           read_fun = readRDS)
transactions %<>%      # note the %<>% combination pipe plus re-assign operator
                       # remember the idea of idempotence from the summary statistics course?
  mutate(appliance_purchase_factor = factor(appliance_purchase, levels = c(0, 1), labels = c("No", "Yes")), 
         appliance_purchase_binary = appliance_purchase)
```

# 2. Send your designated reviewer the boxplot from rerunning the top models using the bootstrap

```{r rerunning_top_models, echo = FALSE, warning = FALSE}
# Create bootstrap model function to run top models
boot_train <- function(form){
  train(formula(form), data=transactions %>% 
          select(-appliance_purchase_factor
                 , -appliance_purchase_binary
                 ,-customer_id)
        , method='gbm'
        , metric = "ROC"
        , verbose = FALSE
        , trControl=trainControl(method='boot'
                                 , number = 25
                                 , classProbs=TRUE
                                 , summaryFunction=twoClassSummary
                                 , savePredictions = TRUE))
} 

# Set up parallel processing
p_load(doParallel)
doParallel::registerDoParallel(cores = detectCores())

top_models <- readRDS("top_models.rds")

transactions %<>%
  mutate(appliance_purchase = relevel(appliance_purchase_factor, ref = 'Yes')) # changing the order so

bootstrap_results <- data_frame() %>% 
  add_model(boot_train(top_models$form[[1]])
            , desc = paste('boot_train',top_models$desc[[1]])
            , logistic_true = 1) %>% 
    add_model(boot_train(top_models$form[[2]])
            , desc = paste('boot_train',top_models$desc[[2]])
            , logistic_true = 1) %>% 
    add_model(boot_train(top_models$form[[3]])
            , desc = paste('boot_train',top_models$desc[[3]])
            , logistic_true = 1) %>% 
    add_model(boot_train(top_models$form[[4]])
            , desc = paste('boot_train',top_models$desc[[4]])
            , logistic_true = 1) %>% 
    add_model(boot_train(top_models$form[[5]])
            , desc = paste('boot_train',top_models$desc[[5]])
            , logistic_true = 1)

```

```{r boxplot, echo = FALSE}
boxplots <- bootstrap_results %>% 
  select(desc, train_resamples) %>% 
  unnest(train_resamples) %>% 
  ggplot(aes(desc, ROC, group = desc)) + 
  geom_boxplot() + 
  coord_flip()

print(boxplots)
saveRDS(boxplots, file = "bootstrap_boxplots_marks.rds")
```


# 3. Send your designated reviewer the final analysis from creating a regression for the following problem

Using the `watch_transactions` data frame in this project, create a model that predicts watch band purchases.

```{r watch_data, warning = FALSE}
watch_store_trans <- eboxr_read("/Users/curtbergmann/Box Sync/Elicit Education/scholar/regclass/watch_store_trans.RDS",
           read_fun = readRDS)
```

```{r explore}
names(watch_store_trans)
```
There are 9 variables in the dataset, none with missing values. Each row is a unique **customer_id**, a variable we will not use for analysis.

It appears appears the dataset represents a snapshot in time for 10,000 customers, where all variables except **watch_band_purchase** *(1 = purchase, 0 = no pruchase)* capture demographic and historical data.

 **sales** = historical revenue generated by customer
 **frequency** = historical number of shopping visits by customer
 **watch_sales** = historical revenue generated by customer from watch sales
 **belt_units** = historical belts purchased by customer
 **handbag_units** = historical handbags purchased by customer
 **salary** = customer salary 
 **receny_days** = days since last purchase

```{r}
summary(watch_band_purchase ~ ., data = watch_store_trans)
```
* As expected, **customer_id** doesn't effect likelihood to purchase a watch band. 
* **handbag_units** has a positive relationship until very high levels, which probably indicates people who purchase a TON of handbags aren't interested in watches.
* **salary** has the expected positive relationship
* **belt_units** seems to have no effect or even a slighlty negative effect
* **watch_sales** has the expected positive influence
* **recency_days** has the expected negative impact (more days since last purchase = less likelyhood to buy watch band)
* Surprisingly, **frequency** seems to have a slightly negative impact on watch band purchases. Perhaps high frequency buyers tend to purchase other items.
* Finally, **sales** only has a descerable positive impact on watch band purhcases until the higher revenue levels. This and the frequency data could indicate watch bands are a luxury good.

## Modeling

### Initial model
```{r}
formula_all <- as.formula("watch_band_purchase ~ handbag_units + salary + belt_units + watch_sales + recency_days + frequency + sales")

model_results <- data_frame() %>% 
    add_model(lrm(formula_all, data=watch_store_trans, y = TRUE),
            logistic_true = 1,    # what is the value for the predicted dependent variable?
            desc="logistic all variables")

model_results %>%
  select(desc, auc, AIC, topq, R2)

model_results %>%
  group_by(desc) %>%
  select(desc, topq_tbl) %>%
  unnest(topq_tbl) %>% 
  ungroup %>% 
  ggplot(aes(quantile_group_id, cum_conversions, color = desc)) +
  geom_line()
```

### Variable correlations
```{r}
corrgram::corrgram(watch_store_trans %>% select(-customer_id), order = TRUE)
```
**Frequency** and **sales** are highly correlated. Let's run an anova to see which adds more information.
```{r, echo = FALSE}
anova(model_results[[1,'model']], test = "Chisq")
```

Sales looks to add more information. But the anova test is direction sensitive so let's try reversing their order.
```{r, echo = FALSE}
formula_reverse <- as.formula("watch_band_purchase ~ handbag_units + salary + belt_units + watch_sales + recency_days + sales + frequency")
formula_reverse2 <- as.formula("watch_band_purchase ~  sales + frequency +handbag_units + salary + belt_units + watch_sales + recency_days")

model_results %<>% 
      add_model(lrm(formula_reverse, data=watch_store_trans, y = TRUE)
                , logistic_true = 1
                , desc="lrm all reverse sales/frequency") %>% 
        add_model(lrm(formula_reverse2, data=watch_store_trans, y = TRUE)
                , logistic_true = 1
                , desc="lrm sales/frequency first")

anova(model_results[[1,'model']], test = "Chisq")
anova(model_results[[2,'model']], test = "Chisq")
anova(model_results[[3,'model']], test = "Chisq")
```
Doesn't seem to matter much. But before removing a variable let's look at non-linearity by adding a spline. 
```{r, echo = FALSE}
model_results %<>%
  add_model(glm(watch_band_purchase ~ 
                  rcs(handbag_units, 5) +
                  rcs(salary, 5) + 
                  rcs(belt_units, 5) + 
                  rcs(watch_sales, 5) + 
                  rcs(recency_days, 5) + 
                  rcs(sales, 5) + 
                  rcs(frequency, 5)
                , data=watch_store_trans
                , family = 'binomial')
            , logistic_true = 1
            , desc = "glm all with rcs") 

model_results %>% 
  select(desc, auc, topq)

```

The model now performs better. Let's look at which variables benefit from the spline
```{r, echo = FALSE}
summary(model_results[[4,'model']])
```

Yes, it seems only handbag_units, salary, watch_sales, and recency are non-linear. So, let's create a model with rcs() only for those variables..
```{r}
model_results %<>%
  add_model(glm(watch_band_purchase ~ 
                  rcs(handbag_units, 5) +
                  rcs(salary, 5) + 
                  belt_units +
                  rcs(watch_sales,5) + 
                  sales + 
                  frequency
                , data=watch_store_trans
                , family = 'binomial')
            , logistic_true = 1
            , desc = "glm all with rcs for handbags and salary")

model_results %<>%
  add_model(glm(watch_band_purchase ~ 
                  rcs(handbag_units, 5) +
                  rcs(salary, 5) + 
                  belt_units +
                  watch_sales + 
                  sales + 
                  frequency
                , data=watch_store_trans
                , family = 'binomial')
            , logistic_true = 1
            , desc = "glm all with rcs for handbags and salary")
  

model_results %>% 
  select(desc, auc, topq)

```




4. Add `rcs` to all continuous variables
5. Use `anova` from a `glm` model to see how variable order affects changes in variation
6. Use `anova` from an `lrm` model to evaluate the non-linear relationship between dependent and independent variables
7. Add models to a data frame using the `add_model` function
8. Use AIC, AUC, and TOPQ to evaluate your models
8. Use cross validation or the bootstrap on your top models to see if one is really better than another
9. Use `gbm` as a reference model
10. Use `Function` to extract the equation from your final choice
12. Use the `top_q_tbls` and a `topq` plot to explain model performance with your client
